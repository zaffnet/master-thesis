

\section{Chatbot Design Process}
\label{sec:design}


\textbf{Figure~\ref{fig:system}} illustrates an overview of the \sysname system. We first describe the elements of the MI counselling approach relevant to this paper.

\subsection{Motivational Interviewing}
\label{sec:MIdef}
Motivational Interviewing is a talk therapy approach for behaviour change, used by clinicians to help patients (called \emph{clients} in MI) move towards and make healthy behaviour changes. Its central strategy is to engage the client in contemplation around the behaviour and link change to their underlying values. The key to the MI approach is that clients themselves discover their motivation to change; the counsellors should neither be directive nor portray themselves as experts --- instead, they should guide the client without generating discord or increasing the ambivalence to change.

Typical conversational `skills' in MI include asking open-ended \emph{questions} around a behaviour, giving \emph{simple reflections} of client responses (restating these in different words) to encourage continued contemplation, linking the reflections to other relevant history or facts (\emph{complex reflections}) and offering \emph{affirmations} for positive accomplishments.

One key outcome of an MI conversation that the counsellor looks for is the kind of `talk' that the contemplation elicits from the client. \emph{Change Talk} refers to client utterances that indicate the client is contemplating or actively planning to change the behaviour. \emph{Sustain Talk} refers to utterances with reasons why it would be difficult for the client to change, or direct statements of the continuance of the habit. Ambivalent clients tend to oscillate between these two states, and thus appear stuck in their addiction. A core goal of MI is to help clients resolve this ambivalence. Successful MI results in a greater amount of Change Talk than Sustain Talk \cite{Apodaca2009}.


\subsection{Iterative Development of the Chatbot}
Our approach to building an automated counsellor chatbot is to begin with a single prompt of a state-of-the-art LLM, Open AI's GPT-4o model \citep{openai2024gpt4o}.  For consistency, all results presented in this paper are from a specific GPT-4o model, \texttt{gpt-4o-2024-08-06}.

Our research group is a collaboration of engineers and expert clinicians, the latter highly experienced in delivering MI counselling for smoking cessation.

The group used the following informal process to evolve the prompt for the counsellor chatbot: we began with a short, simple prompt (shown in Appendix~\ref{sec:initial_system_prompt}), which asks the model to use its own knowledge of MI. Then, sample conversations were generated between the chatbot and two different kinds of test clients: the first test client (a \emph{virtual} client) was a separate instance of the LLM instructed to play the role of a smoker. The prompt for the virtual client, including its ``backstory'' (a demographic specification and personal history), is given in Appendix~\ref{appendix:virtual_smoker_prompt}. The second test client was one of the human researchers role-playing as a smoker.

The resulting transcripts were then reviewed by the team of engineers and expert MI clinicians and researchers, who identified issues in bi-weekly meetings. The discussions would lead to an improved prompt to address the issues. Each revised prompt was tested with several more counsellor-test-client conversations to see if the improvement was successful.

The list below gives the set of the most important improvements made to the prompt, linked to specific lines of the final prompt (given in Appendix~\ref{sec:system_prompt}) that were changed to make that improvement.

\begin{enumerate}[itemsep=0pt, parsep=0pt]
    \item \textbf{Appropriate utterance length}: It was observed that the chatbot had a tendency to be quite verbose, which would make it sound unnatural and overwhelming to the client. The prompt was modified (in lines 2-3 of Appendix~\ref{sec:system_prompt}) to address this.

    \item \textbf{Accessible Language}: To make \sysname accessible to users from diverse educational and socioeconomic backgrounds, it was instructed to use simple language, avoid complex terminology, and adapt to the client's language. The prompt was modified (in line 2 of Appendix~\ref{sec:system_prompt}) to address this.

    \item \textbf{Avoiding assumptions about nicotine use}: It was observed that the chatbot sometimes made a premature assumption about the nature and extent of the client's smoking. The MI clinicians suggested that a counsellor should enter the conversation with an open mind and let the client describe the amount of smoking. The prompt was modified (in line 6 of Appendix~\ref{sec:system_prompt}) to address this.

    \item \textbf{Improved conversation pace:} The chatbot had the tendency to move into the conversational topic of smoking quickly and put insufficient effort into building rapport with the client. Clinicians emphasized the need to start conversations with icebreakers to create a comfortable environment for the client. The prompt was modified to reflect this in lines 1 and 7.

    \item \textbf{Appropriate timing of the planning phase:} Planning is a crucial step in MI, in which clients begin to think through concrete ideas on how they would bring change to their behaviour. However, guiding clients to begin planning prematurely can be counter-productive and drive them away from change. The prompt was modified in lines 9-13 to give instructions on how and when to move towards the planning phase. A key understanding here is to wait until the client demonstrates a reduced amount of sustain talk.
\end{enumerate}


These iterative discussions continued until the team was (informally) satisfied with the quality and MI adherence of virtual/role-played conversations.


\subsection{Observer Agents}
In addition to the primary counsellor agent, to ensure the chatbot could be deployed safely for end users, we developed observer agents to monitor the conversations between the chatbot and the client. Each observer is built using a prompted GPT-4o instance,
tasked with reviewing specific aspects of the ongoing conversation and can intervene when necessary, as described below.

\subsubsection{The Moderator}
The \textit{moderator} reviews the counsellor's most recent utterance and determines whether it could potentially harm the client. While OpenAI's internal guardrails \citep{openai_safety_update_2024} are highly effective at preventing some forms of harmful content, they do not safeguard against counterproductive counsellor utterances. We designed this observer to have high sensitivity (and, consequently, a high false positive rate). If the moderator deems that the counsellor's utterance is potentially encouraging self-harm (which might include a suggestion to actually smoke), the system re-generates the counsellor's utterance, which is again checked. This process is repeated up to a maximum of five attempts or until the moderator deems the latest utterance ``acceptable''. In all experiments described below, the re-generated counsellor utterance succeeded within four generation attempts and never failed to produce an acceptable utterance.

\subsubsection{Off-Track Conversation Classifier}
We were concerned that some of our participants might intentionally steer the conversation far off from the topic of smoking.
We built a classifier to monitor conversations in real-time to detect if the client is deliberately steering the conversation off-track. Unlike the moderator observer, this classifier was prompt-engineered for a low false positive rate to give the benefit of the doubt to the client. The purpose of this classifier was to identify participants who were not engaging in a serious conversation for removal from the dataset. In an actual deployment, this observer could be used to trigger the end of the conversation.

\subsubsection{End Classifier and Conversation Termination}
The intent to end a conversation can arise from either the client or the counsellor. To ensure the conversation transitions smoothly to an ending and the post-conversation survey, we designed an \textit{end classifier} that monitors the dialogue in real-time and determines if the counsellor or client wishes to finish. If so, the counsellor is instructed to summarize the conversation (a typical MI practice) and ask if the client wishes to continue. If the client does wish to continue, then the conversation is resumed.
