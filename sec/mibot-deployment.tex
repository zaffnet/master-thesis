\section{MIBot System Design}
\label{sec:deployment}


\subsection{Overview of the Application}


MIBot is implemented as a \margindex[MIBot, Deployment]{containerized software system}[Containerization]containerized software system that can be run locally for development and deployed to cloud-based systems. In this section, we discuss the implementation details of MIBot, from the structure of the \margindex[MIBot, Deployment]{python microservice}[Microservice]Python microservice and its integration with the OpenAI API to the containerization and the deployment of the service on Amazon Web Services.

The core of MIBot is a lightweight Python web application built with the \margindex[MIBot, Deployment]{sanic}[Sanic]\texttt{Sanic} framework \cite{pi_sanic}. In MIBot, \texttt{app.py}, the main entry point, uses \texttt{Sanic} to configure routes for all external interactions and instantiates the conversation engine.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\linewidth]{fig/microservice.drawio.pdf} 
  \caption{Overview of the Sanic application that contains MIBot code and exposes REST APIs.}
  \label{fig:microservice}
\end{figure}
An overview of the application's architecture is presented in Figure~\ref{fig:microservice}. When a user sends a request to the \texttt{/chat} endpoint containing their message and \texttt{client\_id}, the web server updates the state of the \margindex[MIBot, Architecture]{conversation}[Conversation] and requests the next turn from it. The \texttt{Conversation} object relays this to the \margindex[MIBot, Architecture]{counsellor}[Counsellor]\texttt{Counsellor}, which in turn sends a request to the OpenAI API with the accumulated conversation history and the current client message, and receives a response containing the generated counsellor turn.

Each \margindex[MIBot, Architecture]{observer}[Observer] attached to the \texttt{Conversation} inherits from a base class defining an asynchronous \texttt{observe()} method. As noted earlier, the \texttt{Moderator} observer screens counsellor utterances for safety and appropriateness; the \texttt{Off-Track Classifier} observer assesses whether the client is steering the conversation away from smoking cessation; and the \texttt{End Classifier} determines when a session should conclude. These observers are implemented as separate GPT-4o API calls with their own prompts. After each turn, the \texttt{Conversation} object iterates over all \texttt{Observer} objects, collects their observations, and makes real-time decisions (e.g., whether to end the conversation) before updating its state. If the generated output from the \texttt{Counsellor} is deemed suitable for the client, it is sent to the client along with relevant metadata.

A single \texttt{Sanic} app can handle multiple clients at once by creating replicas of the \texttt{Conversation} object, each uniquely identified by the \texttt{client\_id}.\footnote{For the human feasibility study, in order to keep track of the participants and their conversations, we explicitly use \texttt{prolific\_id} as \texttt{client\_id}. Prolific (\url{www.prolific.com}) is the platform we use to recruit participants and conduct our feasibility study. See Section~\ref{sec:feasibility} for further details.} The microservice also exposes some additional endpoints: \texttt{/get\_transcript} provides a downloadable transcript of the conversation for post-session analysis; \texttt{/health} returns a simple \texttt{200} response so that load balancers and orchestrators can perform health checks; and \texttt{/info} exposes build metadata such as the current version of the prompt.

\subsection{Containerization}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\linewidth]{fig/container.drawio.pdf} 
  \caption{Containerized Sanic application.}
  \label{fig:containerization}
\end{figure}

For reproducibility and ease of deployment, the microservice is packaged in a Docker container. Containerization provides several advantages for the development, testing, and deployment of MIBot, including environment consistency, portability, isolation, scalability, faster deployment and rollbacks, simplified CI/CD integration, and reproducibility, as discussed in detail by Sloane~\cite{sloane2025containerization}.

The MIBot container image is defined by a \margindex[MIBot, Deployment]{dockerfile}[Dockerfile]\texttt{Dockerfile} specifying the base Python runtime, required dependencies, the source code, and main entry point (\emph{viz.} \texttt{app.py}). This image is stored in Amazon Elastic Container Registry (ECR). The container registry stores all the images built by the CI/CD pipeline, but only the image with the \texttt{production} tag is used for deployment.

\section{Deploying MIBot to AWS}
\label{sec:mibot-deployment}

MIBot is deployed as a service on Amazon \margindex[MIBot, Deployment]{amazon elastic container service (ECS)}[ECS]\textbf{Elastic Container Service (ECS)}. ECS is a fully managed service provided by Amazon Web Services (AWS) that ``simplifies the deployment, management, and scaling of applications using containers'' \cite{aws-ecs-getting-started}. We now discuss each component of ECS.

\subsection{Components of ECS}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.99\linewidth]{fig/deployment.drawio.pdf} 
  \caption{Containerized MIBot application deployed to ECS.}
  \label{fig:ecs-components}
\end{figure}

\paragraph{1. ECS Cluster:}To deploy MIBot to ECS, we first provisioned an \margindex[MIBot, Deployment, ECS]{ecs cluster}[ECS Cluster]\textbf{ECS cluster} (\texttt{mibot-v6-cluster}). An ECS cluster is a \textit{logical} grouping of heterogeneous compute resources. In the context of AWS, a \textbf{compute resource} is any AWS-managed infrastructure component that provides processing power for running applications or workloads. These resources can be \textbf{user-managed}, like Elastic Cloud Compute (EC2), where users rent virtual machines, or \textbf{fully managed}, like \margindex[MIBot, Deployment, ECS]{aws fargate}[Fargate]AWS Fargate, which is used to run containerized applications without direct server management. A cluster is therefore a logical grouping of such compute resources.

In our ECS cluster, however, we only used \textbf{AWS Fargate} as the computing resource. In addition to allowing for the deployment of the containerized MIBot application without server management, AWS Fargate also offers \emph{spot runs} for cost optimization. In the \texttt{FARGATE\_SPOT} mode, tasks run on spare compute capacity. If a container receives no traffic in the last two hours and AWS reclaims the capacity, the task will be terminated. ECS will detect this event and will almost immediately instantiate a new task for the application.

\paragraph{2. ECS Service:}Inside the ECS cluster, we created an \margindex[MIBot, Deployment, ECS]{ecs service}[ECS Service]\textbf{ECS Service} (\texttt{mibot-v6-service}). The ECS Service contains the deployment configuration of the application, for example, the number of desired replicas of the application (also called \emph{tasks}) that should run at any given time.  For our study, we set this to use two tasks. If one of the tasks fails, the ECS Service replaces it automatically. It can also be configured to increase the number of tasks when it detects higher-than-normal traffic. The Service is connected to an Elastic Load Balancer (ELB) to distribute incoming traffic evenly among tasks. It also defines deployment (rolling update, blue/green deployment) and rollback strategies, and can leverage the AWS circuit breaker to roll back failed deployments automatically.

\paragraph{3. ECS Task Definition:}The final component in the deployment of MIBot is defining a \margindex[MIBot, Deployment, ECS]{ecs task definition}[ECS Task]\textbf{Task}. A \texttt{Task} runs a specific container after downloading it from the Elastic Container Registry (ECR). The \texttt{Task} definition specifies environment variables and API credentials that are securely stored in AWS Systems Manager Parameter Store and are injected into the container (e.g., \texttt{OPENAI\_API\_KEY}) when the task is started. It further defines a \emph{health check} for the container. The health check sends a request to the \texttt{/health} endpoint on the container's port~80 every five minutes. If the response is anything other than \texttt{OK 200} or it does not get a response within one minute, it deems the container unhealthy. The \texttt{Service} terminates the \texttt{Task} and replaces it with a new one. The task definition further specifies the required CPU and memory (1024 CPU units (1 vCPU) and 4~GB, respectively, in the case of MIBot). The containers also mount a persistent Amazon Elastic File System (EFS) volume to store conversation transcripts and evaluation metrics. Furthermore, all container logs are written to AWS CloudWatch for retrospective analysis of the system's behaviour.

\subsection{Other Components of the Deployment}

\paragraph{Load Balancer:}We configured an \margindex[MIBot, Deployment]{elastic load balancer (ELB)}[ELB]Elastic Load Balancer (\texttt{mibot-elb}) with three subnets for high availability, meaning we have three instances of load balancers in three different Availability Zones. The load balancers are \emph{application} load balancers (ALB)~\cite{aws_alb}, which are internet-facing and associated with a security group permitting inbound traffic on port 443. The DNS names allow external users to connect to the service through a custom domain name~\cite{shopify_domain_seo}. The ALB routes incoming HTTP requests to the ECS service's target group and internal health check requests to the \texttt{/health} endpoint.

\paragraph{API Gateway:}We also provisioned an \margindex[MIBot, Deployment]{api gateway}[API Gateway]AWS API Gateway, which acts as a reverse proxy and enables secure TLS termination and request throttling. The gateway exposes HTTPS endpoints for \texttt{/chat}, \texttt{/get\_transcript}, \texttt{/health}, \texttt{/info}, and \texttt{/s3\_upload}. Each path includes \texttt{OPTIONS} methods to enable cross-origin requests and defines the expected response headers. This prevents client browsers from blocking requests due to Cross-Origin Resource Sharing (CORS) policies or displaying security warnings.

\paragraph{DataSync:}Conversation transcripts and metadata are stored on both an encrypted EFS volume and AWS S3 only when the participant clicks on the final Submit button at the end of the study session. EFS acts as a redundant data layer in case the upload to S3 fails. For eventual consistency, we periodically copy files from EFS to S3 using \margindex[MIBot, Deployment]{aws datasync}[DataSync]AWS DataSync, which runs a daily CRON job.

\subsection{Deployment Pipeline}
We adopted DevOps practices for automated deployment. Every time we push a special `\texttt{production}` Git tag to the remote main branch, a \margindex[MIBot, Deployment]{deployment pipeline}[CI/CD]GitHub workflow builds the Docker image, runs unit tests, and, if tests pass, pushes the image to Amazon ECR. Another workflow triggers a CloudFormation deployment that updates the ECS task definition with the new image tag and performs a rolling deployment of the ECS Service. Deployment uses a circuit breaker configuration: if the service fails health checks, the rollout is automatically rolled back to the previous stable revision. By integrating the deployment pipeline into version control, we ensured automated deployments tied to code changes.
