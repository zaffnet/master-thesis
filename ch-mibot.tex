\chapter{Design \& Deployment of MIBot for Human Feasibility Study}
\label{ch:mibot}

The recent advances in Large Language Models (LLMs) present an opportunity to automate various forms of mental health talk therapy, including Motivational Interviewing (MI) for smoking cessation. This is a significant area of need, as over half of all smokers are in an ambivalent state, where they are aware of the harms of smoking but have not yet committed to quitting \citep{Babb2017}. Guiding these individuals towards a decision to quit is a key precursor for any successful quit attempt \citep{West2006}.

This chapter details the design and deployment of \margindex{MIBot}MIBot. It is a \margindex[MIBot]{fully generative}[generative], LLM-based MI chatbot created for this purpose. The work builds on a predecessor system, MIBot v5.2 \citep{info:doi/10.2196/49132}, which, being partially scripted, had limitations in conversational naturalness. The development and evaluation of the current MIBot system are described in detail by \citet{mahmood-etal-2025-fully}. This chapter complements that work by focusing on the technologies, design considerations, and implementation choices underlying the chatbot's deployment for a human feasibility study.

The chapter is structured as follows. Section~\ref{sec:iterative-development} outlines the clinician-informed, iterative process used to develop the chatbot's core prompt. Section~\ref{sec:observers} describes the system architecture, including the observer agents designed to ensure safety and conversational coherence. Section~\ref{sec:deployment} details the technical implementation and deployment of the MIBot service using containerization and cloud infrastructure. Finally, Section~\ref{sec:feasibility} describes the design of the human feasibility study used to evaluate MIBot's effectiveness, focusing on four key dimensions: changes in participants' readiness to quit, perceived empathy (CARE scale), the chatbot's adherence to MI principles (AutoMISC), and its ability to elicit client change talk. Chapter~\ref{ch:mibot-eval} reports the results of this study.




\section{Chatbot Design Process}
\label{sec:iterative-development}

The design of MIBot followed a \margindex[MIBot]{clinician-informed}[clinician-informed] design process. This was an \margindex[MIBot]{iterative process}[iterative] that combined expertise in MI with prompt engineering for a state-of-the-art LLM \cite{openai2024gpt4ocard}.

\subsection{Single-Prompt Architecture Rationale}
\label{sec:single-prompt-rationale}

The initial architectural decision for MIBot was to use a \margindex[MIBot]{single-prompt architecture}[Single-prompt Arch.]single, comprehensive prompt to define the chatbot's behaviour. This ``start simple'' approach is a fundamental engineering principle, where the goal is to first build and test the most straightforward solution before considering more complex alternatives. In the context of an MI chatbot, a single prompt that encapsulates the counsellor's entire persona, skills, and decision-making logic provides a strong baseline for evaluation. If this simple architecture can be shown to be effective, it avoids the premature introduction of more complex systems, such as those involving multiple, dynamically selected prompts or a separate "Behavior-Change" selector module. The iterative development process described in the following section was therefore focused on refining this single prompt to its maximum potential.

\subsection{Iterative Prompt Development}
The MIBot prompt was refined through structured feedback from both engineers and experienced MI clinicians who regularly met biweekly over the course of development. The process began with a minimal prompt that instructed the model to act as an MI counsellor. This baseline was tested through simulated counselling sessions with two types of test clients:

\begin{enumerate}
    \item \textbf{\margindex[MIBot]{virtual smoker clients}[Virtual Smokers]Virtual smoker clients}, which were separate GPT-4o instances that were given detailed backstories and instructed to role-play smokers with varying attitudes toward quitting. Chapter~\ref{ch:synthetic-smoker} describes in detail the creation of these basic LLM-based virtual smokers, and subsequent research to enhance their capabilities.
    \item \textbf{\margindex[MIBot]{human role-playing}[Human Role-play]Human role-playing as smokers} --- members of our research team who adopted smoker personas and interacted with the chatbot to test how each version of the prompt behaved in different scenarios.
\end{enumerate}

After each testing cycle, transcripts were reviewed in bi-weekly meetings to identify shortcomings in the appropriate use of MI skills, adherence to MI principles, tone, pacing, and client engagement, among other aspects. These findings informed successive prompt revisions. 
This process led to several key prompt revisions:


\begin{enumerate}
    \item \textbf{\margindex[MIBot, prompt]{Utterance Length Control}[Length Control]Utterance Length Control.} Early versions tended toward long, paragraph-like responses, which risked dominating the conversation, which is the antithesis of MI, in which the client leads the process of contemplation.  The prompt was amended to include explicit length constraints (``Keep your responses short. Do not talk more than your client.'') and to encourage brevity while maintaining reflective depth.

    \item \textbf{\margindex[MIBot, prompt]{Accessible Language}[Accessible Lang.]Accessible Language.} To ensure inclusivity across educational and socioeconomic backgrounds, clinicians requested avoidance of jargon and adaptation to the client's linguistic style. This was codified in the prompt as ``Avoid using complex terminology … maintain simplicity in the conversation.''

    \item \textbf{\margindex[MIBot, prompt]{Assumption Avoidance}[No Assumptions]Avoidance of Assumptions.} The model occasionally assumed the client's nicotine consumption patterns. The prompt was revised to explicitly instruct the counsellor that ``You don't know anything about the client's nicotine use yet'' to preserve an open, exploratory stance.

    \item \textbf{\margindex[MIBot, prompt]{Rapport-Building}[Rapport]Rapport-Building Before Smoking Focus.} Initial versions of the prompt engaged with smoking behaviour too early, bypassing engagement and focusing stages. The revised prompt added guidance to ``open the conversation with a general greeting and friendly interaction'' before gradually steering toward smoking ambivalence.

    \item \textbf{Guarding Against \margindex[MIBot, prompt]{Premature Planning}[No Planning]Premature Planning.} Planning is an MI process best introduced after sufficient evocation of Change Talk. The prompt included multi-step criteria for initiating planning, explicitly instructing the model to wait for reduced Sustain Talk and to confirm readiness before launching into planning and discussing concrete steps to take towards quitting.

    
\end{enumerate}



This iterative process continued until virtual and role-played conversations consistently met MI quality expectations as determined by an informal consensus of the team.


Tables~\ref{tab:initial-system-prompt} and \ref{tab:final-system-prompt} showcase how the prompt evolved from a simple instruction about the LLM's role to a comprehensive guideline addressing issues identified in the chatbot's performance.

\include{tab/initial-final-prompts}


\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\linewidth]{fig/sysdiag.pdf} 
  \caption{Overview of the MIBot system, taken from \citet{mahmood-etal-2025-fully}}
  \label{fig:sysdiag}
\end{figure}

\section{Observers}
\label{sec:observers}
To enhance safety in the deployment of MIBot, the core counsellor agent was augmented with a set of \margindex[MIBot]{observer agents}[Observer Agents]\textit{observer agents}, independent instances of GPT-4o prompted to monitor specific aspects of the conversation in real time.  The output of these agents is used to intervene when necessary. Each observer was specialized through prompt engineering to perform a specific task in real time.

\subsection{Moderator}
The \margindex[MIBot, Observers]{Moderator}\textit{Moderator} evaluates the counsellor's most recent utterance for potential harm before it is displayed to the client. While OpenAI's internal safety systems mitigate many risks, they do not address all possible counterproductive counselling behaviours, such as inadvertently reinforcing \emph{sustain talk} or suggesting self-harm. The Moderator was deliberately configured for high sensitivity, accepting a higher false positive rate to reduce the risk of harmful or counterproductive content. If a counsellor's utterance is flagged, it is regenerated and re-evaluated, with up to five regeneration attempts permitted. In all study conversations, an acceptable utterance was produced within four attempts, and no session failed to pass moderation.

\subsection{Off-Track Conversation Classifier}
The \margindex[MIBot, Observers]{Off-Track Classifier}[Off-Track]\textit{Off-Track Classifier} detects when a client is steering the dialogue away from smoking cessation in a deliberate or sustained manner. Its prompt was tuned for low false positive rates to preserve conversational flexibility. In the feasibility study described in Chapter~\ref{ch:mibot-eval}, this observer's primary role was retrospective --- identifying conversations for exclusion where the participant was not engaging seriously with the intervention. In a live deployment, it can be a used to trigger early termination or redirection to the main topic.

\subsection{End Classifier \& Termination Process}
The \margindex[MIBot, Observers]{End Classifier}[End Chat]\textit{End Classifier} monitors both parties' dialogue to determine if the conversation is reaching a natural conclusion. It prioritizes the client's intent when making this determination, ensuring the conversation is not ended prematurely. Upon detecting an intent to close, it instructs the counsellor to deliver a concise summary of key discussion points --- a standard MI practice --- and to confirm with the client whether they wish to continue. If the client declines, the conversation is terminated and any post-session procedures, such as surveys, are initiated.


\textbf{Design Rationale:} All observers were implemented as separate, stateless LLM calls, each with prompts tailored to their decision criteria. This modular approach allowed independent refinement of their sensitivity–specificity balance without impacting the primary counsellor prompt. The Moderator favoured recall over precision to err on the side of client safety, whereas the Off-Track Classifier did the opposite, favouring conversational autonomy. The End Classifier's logic explicitly distinguished between topic changes and true conversation endings, reducing false terminations.


The prompted GPT-4o, together with observers, constitute the complete MIBot system, as illustrated in Figure~\ref{fig:sysdiag}.


\input{sec/mibot-deployment}

\input{sec/feasibility}
