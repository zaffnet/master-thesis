\chapter{Conclusion and Future Directions}
\label{ch:conclusion}

This thesis has examined the development and evaluation of a fully generative motivational interviewing chatbot, designed to support smokers in moving towards the decision to quit. We investigated how to create synthetic smokers from human smokers through attribute installation and validated our approach using clinically and linguistically grounded metrics of behaviour change. Using such synthetic patients to train therapists is a practical application of this work.


\section{Summary of Contributions}

The primary contributions of this thesis are twofold. First, we demonstrated the feasibility of creating a generative MI chatbot capable of empathetic and effective conversations with smokers, with MIBot showing good alignment with MI principles. Second, we developed and validated a methodology for installing attributes into synthetic smokers. While not perfect, this method---with its reliable validation criteria of fidelity, distributional representativeness, and fairness---offers a solid foundation for future research into creating synthetic agents for training counsellors.


\section{Future Directions}
The findings of this thesis open up several potential avenues for future research, both in the field of mental health chatbots and in the use of synthetic user personas.

\begin{itemize}
	\item While MIBot was designed to be empathetic, a large gap in empathy remains between MIBot and humans. Future chatbots could be made even more effective by tailoring their responses to the individual user's personality, communication style, and emotional state. This could be achieved by incorporating more advanced user modelling techniques.
	\item Future research should investigate how chatbots like MIBot can be integrated into existing clinical workflows. For example, a chatbot could be used to provide support to patients between therapy sessions, with the conversation history being made available to the human therapist (with the user's consent). This would create a blended model of care that combines the scalability of AI with the expertise of human professionals.
	\item While our evaluation of MIBot showed encouraging short-term results, more research is needed to understand the long-term efficacy of such chatbots. This would involve conducting longitudinal studies and randomized controlled trials with real smokers to track their progress over time and assess the chatbot's effect on their cessation journey.
        \item We defined fairness (or uniform fidelity) as one of the main requirements of successful validation that a desired attribute has been installed (\Cref{uniform-fidelity}). We also showed that, even when starting with a sex-balanced dataset, the correlation of \%CT for females was lower than that for males, indicating that our method did not uniformly install `resistance to change'. Investigating the root cause of this phenomenon and its mitigation warrants further attention.
	\item A potential technique for controlling the attributes of generated personas is the use of \textbf{steering vectors}. This method allows us to guide the LLM's output without the need for costly fine-tuning. The process involves manipulating the model's internal activations to steer behaviour. This technique offers fine-grained control over attribute installation, something not achievable by prompting alone.
\end{itemize}

The concept of synthetic smokers, or more broadly, LLM-based personas, is still in its infancy, and we anticipate that future work will continue to refine this methodology and examine new ways to install specific attributes into these personas.

\section{Concluding Remarks}

The intersection of large language models and mental health holds immense promise for the future of healthcare. This thesis has demonstrated how generative AI can be used to create an empathetic and safe chatbot. Concurrently, advancements in the creation of synthetic patients could help these chatbots become better mental health counsellors, reducing the reliance on prohibitively expensive datasets of human-human and chatbot-human counselling sessions for fine-tuning or alignment. While many challenges remain, our mathematical exposition of validating attribute installation will serve future researchers in this area. In the spirit of open research, and to contribute towards accessible mental health support, we have made the dataset from our human feasibility study on MIBot public\footnote{The dataset can be found online: \url{https://github.com/cimhasgithub/MIBOT\_ACL2025}.}.
